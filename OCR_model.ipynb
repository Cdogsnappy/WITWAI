{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Meau\\Python\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/dataset/european_images.csv', index_col=0)\n",
    "df['img_path'] = [f\"./Data/dataset/{index}.png\" for index in df.index]\n",
    "df['text'] = 0\n",
    "df['confidence'] = 0\n",
    "df['bbox_']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to determine the best OCR model for this.\n",
    "\n",
    "Candidates:\n",
    "    easyocr (built in, uses pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Text Recognition\n",
    "1. It's important to note that we're looking at a plethora of European languages, which will employ various modifications to the latin script, cyrillic, etc. \n",
    "2. As such, multiple OCR readers can be employed. We can run each reader on an image, extract the confidence and various pieces of text above some threshold, and then input the collected data to our classifier.\n",
    "3. We could also use a reader with multiple languages in the list. This will remove the ability to handle different languages differently, but that may be better to avoid data leakage?\n",
    "4. It may be necessary to prune the 'Google' labels from the images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR Text Recognition: Language definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.jaided.ai/easyocr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### I need to handle each of these... maybe if we use the USA dataset we won't have to use as many OCR readers \n",
    "reader_be = easyocr.Reader(['be'])\n",
    "reader_bg = easyocr.Reader(['bg'])\n",
    "reader_cs = easyocr.Reader(['cs'])\n",
    "reader_cy = easyocr.Reader(['cy'])\n",
    "reader_da = easyocr.Reader(['da'])\n",
    "reader_de = easyocr.Reader(['de'])\n",
    "reader_en = easyocr.Reader(['en'])\n",
    "reader_es = easyocr.Reader(['es'])\n",
    "reader_et = easyocr.Reader(['et'])\n",
    "reader_fr = easyocr.Reader(['fr'])\n",
    "reader_ga = easyocr.Reader(['ga'])\n",
    "reader_hr = easyocr.Reader(['hr'])\n",
    "reader_hu = easyocr.Reader(['hu'])\n",
    "reader_is = easyocr.Reader(['is'])\n",
    "reader_it = easyocr.Reader(['it'])\n",
    "reader_la = easyocr.Reader(['la'])\n",
    "reader_lt = easyocr.Reader(['lt'])\n",
    "reader_lv = easyocr.Reader(['lv'])\n",
    "reader_mt = easyocr.Reader(['mt'])\n",
    "reader_nl = easyocr.Reader(['nl'])\n",
    "reader_no = easyocr.Reader(['no'])\n",
    "reader_pl = easyocr.Reader(['pl'])\n",
    "reader_ro = easyocr.Reader(['ro'])\n",
    "reader_ru = easyocr.Reader(['ru'])\n",
    "reader_rs = easyocr.Reader(['rs_latin'])\n",
    "reader_rc = easyocr.Reader(['rs_cyrillic'])\n",
    "reader_sk = easyocr.Reader(['sk'])\n",
    "reader_sl = easyocr.Reader(['sl'])\n",
    "reader_sq = easyocr.Reader(['sq'])\n",
    "reader_sv = easyocr.Reader(['sv'])\n",
    "reader_uk = easyocr.Reader(['uk'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either only store text above a certain threshold for all, or only store text above a certain threshold for each language.\n",
    "Could train an NN to predict language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OCR_extraction(path):\n",
    "    results =  reader_en.readtext(path)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    results = OCR_extraction(row['img_path'])\n",
    "    bbox_ = []\n",
    "    text = []\n",
    "    confidence = []\n",
    "    for result in results:\n",
    "        bbox_.append(result[0])\n",
    "        text.append(result[1])\n",
    "        confidence.append(result[2])\n",
    "    df.at[index, \"bbox_\"] = bbox_\n",
    "    df.at[index, \"text\"] = text\n",
    "    df.at[index, \"confidence\"] = confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_be = easyocr.Reader(['be'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strip Google watermarks from detected text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either drop from extracted data, or remove from init image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
