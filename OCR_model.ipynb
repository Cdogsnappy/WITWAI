{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import easyocr\n",
    "from collections import Counter\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/dataset/european_images.csv', index_col=0)\n",
    "df['img_path'] = [f\"./Data/dataset/{index}.png\" for index in df.index]\n",
    "df['text'] =  pd.Series(dtype='object')\n",
    "df['confidence'] =  pd.Series(dtype='object')\n",
    "df['bbox'] =  pd.Series(dtype='object')\n",
    "df['lang'] = pd.Series(None)\n",
    "df['best_confidence'] = pd.Series(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to determine the best OCR model for this.\n",
    "\n",
    "Candidates:\n",
    "    easyocr (built in, uses pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Text Recognition\n",
    "1. It's important to note that we're looking at a plethora of European languages, which will employ various modifications to the latin script, cyrillic, etc. \n",
    "2. As such, multiple OCR readers can be employed. We can run each reader on an image, extract the confidence and various pieces of text above some threshold, and then input the collected data to our classifier.\n",
    "3. We could also use a reader with multiple languages in the list. This will remove the ability to handle different languages differently, but that may be better to avoid data leakage?\n",
    "4. It may be necessary to prune the 'Google' labels from the images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR Text Recognition: Language definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.jaided.ai/easyocr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ocr_reader():\n",
    "    def __init__(self, lang):\n",
    "        self.lang = lang\n",
    "        self.reader = easyocr.Reader([lang])\n",
    "    \n",
    "    def __call__(self, df):\n",
    "        min_length = 3\n",
    "        self.df_results = df.copy()\n",
    "        \n",
    "        for index, row in self.df_results.iterrows():\n",
    "            \n",
    "            results = self.OCR_extraction(row['img_path'], self.reader)\n",
    "            \n",
    "            bbox_ = []\n",
    "            text = []\n",
    "            confidence = []\n",
    "            for result in results:\n",
    "                if len(result[1]) >= min_length:\n",
    "                    bbox_.append(result[0])\n",
    "                    text.append(result[1])\n",
    "                    confidence.append(result[2])\n",
    "                \n",
    "            self.df_results.at[index, \"bbox\"] = bbox_\n",
    "            self.df_results.at[index, \"text\"] = text\n",
    "            self.df_results.at[index, \"confidence\"] = confidence\n",
    "        \n",
    "        return self.df_results\n",
    "    def OCR_extraction(self, path, reader):\n",
    "        results =  reader.readtext(path)\n",
    "        return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = {\n",
    "    \"be\": \"be\",\n",
    "    \"bg\": \"bg\",\n",
    "    \"cs\": \"cs\",\n",
    "    \"cy\": \"cy\",\n",
    "    \"da\": \"da\",\n",
    "    \"de\": \"de\",\n",
    "    \"en\": \"en\",\n",
    "    \"es\": \"es\",\n",
    "    \"et\": \"et\",\n",
    "    \"fr\": \"fr\",\n",
    "    \"ga\": \"ga\",\n",
    "    \"hr\": \"hr\",\n",
    "    \"hu\": \"hu\",\n",
    "    \"is\": \"is\",\n",
    "    \"it\": \"it\",\n",
    "    \"la\": \"la\",\n",
    "    \"lt\": \"lt\",\n",
    "    \"lv\": \"lv\",\n",
    "    \"mt\": \"mt\",\n",
    "    \"nl\": \"nl\",\n",
    "    \"no\": \"no\",\n",
    "    \"pl\": \"pl\",\n",
    "    \"pt\": \"pt\",\n",
    "    \"ro\": \"ro\",\n",
    "    \"ru\": \"ru\",\n",
    "    \"rs_latin\": \"rs\",\n",
    "    \"rs_cyrillic\": \"rc\",\n",
    "    \"sk\": \"sk\",\n",
    "    \"sl\": \"sl\",\n",
    "    \"sq\": \"sq\",\n",
    "    \"sv\": \"sv\",\n",
    "    \"tr\": \"tr\",\n",
    "    \"uk\": \"uk\"\n",
    "}\n",
    "\n",
    "Readers = {}\n",
    "\n",
    "for key, lang in languages.items():\n",
    "    Readers[lang] = ocr_reader(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either only store text above a certain threshold for all, or only store text above a certain threshold for each language.\n",
    "On CPU, roughly 3s to initialize the OCR reader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strip Google watermarks from detected text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating text for each image for each reader, then using manual pruning to determine which labels to drop for each language.\n",
    "These can then be associated with the correct language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the english reader, identify matching watermark text, determine the bounding box, and mask the image for that watermark.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OCR_extraction(path, reader):\n",
    "    results =  reader.readtext(path)\n",
    "    return results\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.makedirs(\"./Data/masked_for_ocr/\", exist_ok=True)\n",
    "\n",
    "reader_en = Readers[\"en\"].reader\n",
    "\n",
    "watermarks = [\"cgoogle\", \"cgccgle\", \"cgcogle\", \"cgocgle\", \"google\", \"gccgle\", \"gcogle\", \"gocgle\", \"gocnle\", \"gcogie\", \"oogle\"]\n",
    "\n",
    "### For each image, generate a mask (initially blank). Use this to mask results for the other readers.\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    ### Generating the mask with the english reader, filtering out the sections of the image containing the \"Google\" watermark.\n",
    "    image = cv2.imread(row['img_path'])\n",
    "    mask = np.ones(image.shape[:2], dtype=np.uint8) * 255\n",
    "    results = OCR_extraction(row['img_path'], reader_en)\n",
    "    \n",
    "    bbox_ = []\n",
    "    text = []\n",
    "    confidence = []\n",
    "    for result in results:\n",
    "        bbox_.append(result[0])\n",
    "        text.append(result[1])\n",
    "        confidence.append(result[2])\n",
    "    \n",
    "    for idx, t in enumerate(text):\n",
    "        ### Filtereing text matching the filter, or text with less than min_length characters (meaningless)\n",
    "        min_length = 3\n",
    "        if any(watermark.upper() in t.upper() for watermark in watermarks) or len(t) <= min_length:\n",
    "            corners = bbox_[idx]\n",
    "            x0, y0 = np.array(corners[0], dtype=np.int32) ### Top left corner\n",
    "            x1, y1 = np.array(corners[2], dtype=np.int32) ### Bottom right corner\n",
    "            cv2.rectangle(mask, (x0, y0), (x1, y1), 0, -1)\n",
    "        else:\n",
    "            print(f\"Text {t.upper()} passed the filter for img index {index} and confidence {confidence[idx]}\")\n",
    "    \n",
    "    ### We now have a masked image instead of the original image. Other lang readers can now use this image.\n",
    "    masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    ### Store the images in a new directory (masked_for_ocr/) so that I only have to do this once\n",
    "    cv2.imwrite(f\"./Data/masked_for_ocr/{index}.png\", masked_image)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_df = pd.read_csv('./Data/dataset/european_images.csv', index_col=0)\n",
    "masked_df['img_path'] = [f\"./Data/masked_for_ocr/{index}.png\" for index in df.index]\n",
    "masked_df['text'] =  pd.Series(dtype='object')\n",
    "masked_df['confidence'] =  pd.Series(dtype='object')\n",
    "masked_df['bbox'] =  pd.Series(dtype='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now, with the text extracted from the masked images, we can set confidence thresholds, and only keep results above specific thresholds.\n",
    "\n",
    "##### Identify the language with the highest confidence, and use this as our guessed label\n",
    "##### Additionally, we can extract text and pass forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Full_Results = {}\n",
    "for lang, reader in Readers.items():\n",
    "    Full_Results[lang] = reader(masked_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pass extracted text through LLM to predict country or language\n",
    "Here I am following coding worst practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.1\n",
    "### For each row, iterate through the language DF and identify the highest confidence text\n",
    "### If no text was found, \"best_lang\" = None and thus df['lang'] = None\n",
    "for idx, _ in df.iterrows():\n",
    "    best_confidence = 0.0\n",
    "    best_lang = None\n",
    "    best_text = \"\"\n",
    "    for lang, lang_df in Full_Results.items():\n",
    "        if idx in lang_df.index:\n",
    "            row = lang_df.loc[idx]\n",
    "            if row['text'] is not None and row['text'] != []:\n",
    "                ### Handle single and full\n",
    "                #print(f\"Row confidence: {row['confidence']}\")\n",
    "                cidx = np.argmax(row['confidence'])\n",
    "                if row['confidence'][cidx] > best_confidence:\n",
    "                    best_confidence = row['confidence'][cidx]\n",
    "                    best_lang = lang\n",
    "                    best_text = row['text'][cidx]\n",
    "    if best_confidence > THRESHOLD:\n",
    "    \n",
    "        df.at[idx, 'best_confidence'] = best_confidence\n",
    "        df.at[idx, 'lang'] = best_lang\n",
    "        print(f\"For image {idx}, lang found is {best_lang} with text {best_text}\")\n",
    "\n",
    "print\n",
    "df.to_csv('./Outputs/OCR_results.csv', index=True)\n",
    "\n",
    "### Pass this through feedforward, or to LLM? Could just tokenize it and pass it forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the lang data for OH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./Outputs/languages.json', 'w') as json_file:\n",
    "    json.dump(languages, json_file, indent = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
